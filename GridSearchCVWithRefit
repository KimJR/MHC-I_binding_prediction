from sklearn.ensemble import GradientBoostingClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.ensemble import ExtraTreesClassifier
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import AdaBoostClassifier
from sklearn import svm
from sklearn.metrics import accuracy_score
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import cross_val_predict
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import GridSearchCV
from sklearn import preprocessing
from sklearn.utils.class_weight import compute_sample_weight


import random
import numpy as np
import random
from sklearn.model_selection import train_test_split
import sklearn.metrics

def A():
    return [-0.57, 0.39, -0.96, -0.61, -0.69]

def R():
    return [-0.40, -0.83, -0.61, 1.26, -0.28]

def N():
    return [-0.70, -0.63, -1.47, 1.02, 1.06]

def D():
    return [-1.62, -0.52, -0.67, 1.02, 1.47]

def C():
    return [0.07, 2.04, 0.65, -1.13, -0.39]

def Q():
    return [-0.05, -1.50, -0.67, 0.49, 0.21]

def E():
    return [-0.64, -1.59, -0.39, 0.69, 1.04]

def G():
    return [-0.90, 0.87, -0.36, 1.08, 1.95]

def H():
    return [0.73, -0.67, -0.42, 1.13, 0.99]

def I():
    return [0.59, 0.79, 1.44, -1.90, -0.93]

def L():
    return [0.65, 0.84, 1.25, -0.99, -1.90]

def K():
    return [-0.64, -1.19, -0.65, 0.68, -0.13]

def M():
    return [0.76, 0.05, 0.06, -0.62, -1.59]

def F():
    return [1.87, 1.04, 1.28, -0.61, -0.16]

def P():
    return [-1.82, -0.63, 0.32, 0.03, 0.68]

def S():
    return [-0.39, -0.27, -1.51, -0.25, 0.31]

def T():
    return [-0.04, -0.30, -0.82, -1.02, -0.04]

def W():
    return [1.38, 1.69, 1.91, 1.07, -0.05]

def Y():
    return [1.75, 0.11, 0.65, 0.21, -0.41]

def V():
    return [-0.02, 0.30, 0.97, -1.55, -1.16]

def BLOMAP(char):
    switcher = {
        'A': A(),
        'R': R(),
        'N': N(),
        'D': D(),
        'C': C(),
        'Q': Q(),
        'E': E(),
        'G': G(),
        'H': H(),
        'I': I(),
        'L': L(),
        'K': K(),
        'M': M(),
        'F': F(),
        'P': P(),
        'S': S(),
        'T': T(),
        'W': W(),
        'Y': Y(),
        'V': V(),
    }
    func = switcher.get(char, lambda: "Char is not a amino acid")
    return func


Training = []
TrainingTargets = []
Validation = []
ValidationTargets = []


filename = 'project_training.txt'
file = open(filename, 'r')
lines = list(file)
File = []
Peptides = []
Targets = []

for element in lines:
    element = element.replace('\r', '')
    element = element.replace('\n', '')
    element = element.split('\t')
    File.append(element)

# delete header row
File.pop(0)
# shuffle the dataset
random.shuffle(File)
for element in enumerate(File[0::]):
    for peptide in element[1][0:1:]:
        ascii = []
        for char in peptide:
            encoded = BLOMAP(char)
            ascii.append(encoded[0])
            ascii.append(encoded[1])
            ascii.append(encoded[2])
            ascii.append(encoded[3])
            ascii.append(encoded[4])
        File[element[0]][0] = ascii
        Peptides.append(File[element[0]][0])
        Targets.append(int(File[element[0]][2]))

for j in range(10):

    #Verschiedene Classifier aukommentiert, damit man nicht alles immer tippen muss


    clf = GradientBoostingClassifier(n_estimators=160, learning_rate=0.04, min_samples_split=12, min_samples_leaf=20 ,max_depth=5, subsample=0.8)
    #clf = svm.SVC(C=5, gamma=0.016, kernel='rbf')
    #clf = AdaBoostClassifier(n_estimators=150, learning_rate=0.04)
    #clf = RandomForestClassifier(n_estimators=100, max_depth=None, min_samples_split=2, random_state=0)

    parametersGradient = {'n_estimators': np.arange(50,150,10), 'learning_rate': np.arange(0.01, 0.1, 0.01),'min_samples_split': np.arange(40, 80, 10), 'min_samples_leaf': np.arange(40,80,10)}
    parametersADA = {'n_estimators': np.arange(40, 200, 16), 'learning_rate': np.arange(0.001, 0.1, 0.01)}
    parametersSVM = {'C': [1,50], 'gamma': [0.001, 0.1]}
    Training = []
    TrainingTargets = []
    Validation = []
    ValidationTargets = []
    for x in range(len(File)):
        if random.uniform(0, 1) >= 0: #Hier keine 0 damit wir den Fit durchführen und prüfen können
            Training.append(File[x][0]); TrainingTargets.append(File[x][2])
        else:
            Validation.append(File[x][0]); ValidationTargets.append(File[x][2])
    Training = np.asarray(Training)
    lb = preprocessing.LabelBinarizer()
    TrainingTargets = np.array([number[0] for number in lb.fit_transform(TrainingTargets)])
    d = GridSearchCV(clf, cv=10, param_grid=parametersADA, scoring='roc_auc', refit=True, return_train_score=True)
    Training = []
    TrainingTargets = []
    Validation = []
    ValidationTargets = []
    for x in range(len(File)):
        if random.uniform(0, 1) >= 0.2: #Hier keine 0 damit wir den Fit durchführen und prüfen können
            Training.append(File[x][0]); TrainingTargets.append(File[x][2])
        else:
            Validation.append(File[x][0]); ValidationTargets.append(File[x][2])
    Training = np.asarray(Training)
    lb = preprocessing.LabelBinarizer()
    TrainingTargets = np.array([number[0] for number in lb.fit_transform(TrainingTargets)])
    d.fit(Training, TrainingTargets)
    #print(d.cv_results_)
    print(d.best_params_)
    result = d.predict(Validation)
    print(result)
    print(ValidationTargets)
    #d.cv_results_.keys()
    result1= []
    for i in result: result1.append(str(result[i]))
    #clf.fit(Training, TrainingTargets)
    #result = clf.predict(Validation)
    print (sum (1 for i in range(len(ValidationTargets)) if (result1[i] == ValidationTargets[i]))/(len(ValidationTargets)))
    ones = sum(1 for i in ValidationTargets if i == '1')
    print (ones)
    #print(ValidationTargets)
    Training = []
    TrainingTargets = []
    Validation = []
    ValidationTargets = []

